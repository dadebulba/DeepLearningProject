{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('pytorch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "fb220023fd2800431fe98a81f852d0ad5fc6056086b92ba5142182fcc04964c6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/PersonReID_TensorExtractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6jMA8w_8oOH"
      },
      "source": [
        "# Deep Learning Project - Person Re-Identification evaluation\n",
        "\n",
        "[https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/PersonReID_TensorExtractor.ipynb](https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/PersonReID_TensorExtractor.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8pDzzTQviv0"
      },
      "source": [
        "Importing from Google Drive the dataset.zip and extract into dataset folder, change the path with your dataset location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaPQ91Z78oOI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip \"/content/drive/MyDrive/UNITN/5° anno/Deep Learning 2021/dataset.zip\" -d dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg8kbiHv8oOL"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUDHglK08oOM"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import Image\n",
        "import random\n",
        "import gc\n",
        "random.seed(10)\n",
        "# print cuda info\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda device count: {torch.cuda.device_count()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwZMA17l8oOX"
      },
      "source": [
        "## Define Siamese Network\n",
        "This step is used to load the saved model and use it during testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9__1oD_z8oOX"
      },
      "source": [
        "class Identity(nn.Module):\n",
        "  \"\"\"Identity layer to use into network\"\"\"\n",
        "  def __init__(self):\n",
        "      super(Identity, self).__init__()\n",
        "      \n",
        "  def forward(self, x):\n",
        "      return x\n",
        "\n",
        "class Siamese(nn.Module):\n",
        "  \"\"\"Siamese network using two resnet-50 as branches\"\"\"\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    resnet: trained resnet-50\n",
        "  \"\"\"\n",
        "  def __init__(self, resnet):\n",
        "      super(Siamese, self).__init__()\n",
        "      self.resnet = resnet\n",
        "      self.resnet.fc = Identity()\n",
        "      self.linear = torch.nn.Sequential(\n",
        "        torch.nn.Linear(in_features=2048, out_features=1024),\n",
        "        torch.nn.Linear(in_features=1024, out_features=512),\n",
        "        torch.nn.Sigmoid()\n",
        "      )\n",
        "  \"\"\"\n",
        "  Returns: resulting tensor from input inference into one branch of siamese\n",
        "  Args:\n",
        "    x: input image\n",
        "  \"\"\"\n",
        "  def forward_one(self, x):\n",
        "      x = self.resnet(x)\n",
        "      x = x.view(x.size()[0], -1)\n",
        "      x = self.linear(x)\n",
        "      return x\n",
        "  \"\"\"\n",
        "  Returns: resulting tensors from input inference into siamese\n",
        "  Args:\n",
        "    x1: input image1\n",
        "    x2: input image2\n",
        "  \"\"\"\n",
        "  def forward(self, x1, x2):\n",
        "      out1 = self.forward_one(x1)\n",
        "      out2 = self.forward_one(x2)\n",
        "      return out1, out2\n",
        "\n",
        "'''\n",
        "Returns: fine tuned resnet-50\n",
        "Args:\n",
        "  num_classes: number of classes in the dataset.\n",
        "               This is equal to the number of output neurons.\n",
        "'''\n",
        "def initialize_resnet(num_classes):\n",
        "  #load pre-trained resnet\n",
        "  resnet = torchvision.models.resnet50(pretrained=True)\n",
        "  num_features = resnet.fc.in_features\n",
        "  resnet.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=num_features, out_features=1024),\n",
        "    torch.nn.Linear(in_features=1024, out_features=512),\n",
        "    torch.nn.Linear(in_features=512, out_features=num_classes),\n",
        "    torch.nn.Sigmoid()\n",
        "  )\n",
        "\n",
        "  return resnet"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fINP--L08oOQ"
      },
      "source": [
        "class TestingDataset(Dataset):\n",
        "  \"\"\"People testing dataset containing tuple of images with corresponding names\"\"\"\n",
        "  \n",
        "  \"\"\"\n",
        "  Args:\n",
        "    images: images name\n",
        "    dir: root dir of images\n",
        "  \"\"\"\n",
        "  def __init__(self, images, dir):\n",
        "      self.images = images\n",
        "      self.dir = dir\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "  \"\"\"\n",
        "  Returns: tuple of image tensor and corresponding name\n",
        "  Args:\n",
        "    idx: image index\n",
        "  \"\"\"\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "\n",
        "      img_name = self.images[idx]\n",
        "\n",
        "      image = Image.open(\"%s/%s\" % (self.dir, img_name))\n",
        "      image = T.ToTensor()(image)\n",
        "      image = F.interpolate(image, size=128)\n",
        "\n",
        "      sample = (image, img_name)\n",
        "      return sample"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN2uBss3MwXh"
      },
      "source": [
        "\"\"\"\n",
        "Computes the tensors for specified images and save them to file\n",
        "Args:\n",
        "  net: network used to extract tensors\n",
        "  data_loader: data loader containing the images to infer \n",
        "  target_dir: location where to save the resulting tensors\n",
        "\"\"\"\n",
        "def compute_tensors(net, data_loader, target_dir):\n",
        "  if not os.path.exists(target_dir):\n",
        "    os.mkdir(target_dir)\n",
        "  for idx, (image, image_name) in enumerate(data_loader):\n",
        "    # Compute the forward pass\n",
        "    tensor = image.to('cuda:0')\n",
        "    tensor_to_save = net.forward_one(tensor)\n",
        "    torch.save(tensor_to_save, \"%s/%s.ph\"%(target_dir, image_name[0].split(\".\")[0]))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkS1HHdAYQ60"
      },
      "source": [
        "\"\"\"\n",
        "Setup the network and compute the tensors for test and query datasets \n",
        "Args:\n",
        "  device (optional, default GPU): which device to use\n",
        "  img_root: root images location\n",
        "  model_location: trained siamese model location \n",
        "\"\"\"\n",
        "def extract_tensors(device='cuda:0', img_root='./dataset', model_location=\"/content/drive/MyDrive/UNITN/5° anno/Deep Learning 2021/models/siamese_15epoch_net_reid_resnet50_5epoch\"):\n",
        "  # Instantiates the model\n",
        "  net = initialize_resnet(num_classes=56).to(device)\n",
        "  net = Siamese(net)\n",
        "  net.load_state_dict(torch.load(model_location))\n",
        "  net.to(device)\n",
        "  net.eval()\n",
        "  query = [f for f in listdir(\"%s/queries\"%(img_root))]\n",
        "  test = [f for f in listdir(\"%s/test\"%(img_root))]\n",
        "\n",
        "  testing_dataset = TestingDataset(images=test, dir=\"%s/test\"%(img_root))\n",
        "  test_dataloader = torch.utils.data.DataLoader(testing_dataset, 1, shuffle=False, num_workers=4) #before num_workers=4\n",
        "\n",
        "  query_dataset = TestingDataset(images=query, dir=\"%s/queries\"%(img_root))\n",
        "  query_dataloader = torch.utils.data.DataLoader(query_dataset, 1, shuffle=False, num_workers=2) #before num_workers=4\n",
        "\n",
        "  compute_tensors(net=net, data_loader=query_dataloader, target_dir=\"%s/query_tensors\"%(img_root))\n",
        "  compute_tensors(net=net, data_loader=test_dataloader, target_dir=\"%s/test_tensors\"%(img_root))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAgt94Pk43bU"
      },
      "source": [
        "def main(threshold=0.09, \n",
        "         img_root=\"./dataset\",\n",
        "         query_tensor_dir=\"./query_tensors\", \n",
        "         test_tensor_dir=\"./test_tensors\"):\n",
        "\n",
        "  query_tensors = [f for f in listdir(query_tensor_dir)]\n",
        "  query_images = [f for f in listdir(\"%s/queries\"%(img_root))]\n",
        "  test_tensors = [f for f in listdir(test_tensor_dir)]\n",
        "  test_images = [f for f in listdir(\"%s/test\"%(img_root))]\n",
        "\n",
        "  query_tensors.sort()\n",
        "  query_images.sort()\n",
        "  test_tensors.sort()\n",
        "  test_images.sort()\n",
        "\n",
        "  test_tensors_cuda = []\n",
        "  for test in test_tensors:\n",
        "    test_tensor = torch.load(\"{}/{}\".format(test_tensor_dir, test))\n",
        "    test_tensor.to('cuda:0')\n",
        "    test_tensors_cuda.append(test_tensor)\n",
        "\n",
        "  f = open(\"reid_results.txt\", \"w\")\n",
        "\n",
        "  for idxQ, query in enumerate(query_tensors):\n",
        "    print(query, \"processing\")\n",
        "    query_tensor = torch.load(\"{}/{}\".format(query_tensor_dir, query))\n",
        "    query_tensor.to('cuda:0')\n",
        "\n",
        "    to_print = \"{}:\".format(query_images[idxQ])\n",
        "\n",
        "    for idxT, test in enumerate(test_tensors_cuda):\n",
        "      euclidean_distance = F.pairwise_distance(query_tensor, test)\n",
        "      if euclidean_distance.item() < threshold:\n",
        "        to_print = \"{}{},\".format(to_print, test_images[idxT])\n",
        "\n",
        "    f.write(to_print[:-1])\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "  f.close()\n",
        "      "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFovGLv2EbmU"
      },
      "source": [
        "#This is done to prevent memory overflow and use only the computed tensors during test phase, if you have already the zip files with tensors you can skip this phase\n",
        "extract_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykOukGdcJaVb"
      },
      "source": [
        "## Make a zip containing the tensors if need to save them\n",
        "import shutil\n",
        "shutil.make_archive('query_tensors', 'zip', './dataset/query_tensors')\n",
        "shutil.make_archive('test_tensors', 'zip', './dataset/test_tensors')\n",
        "\n",
        "## Unzip tensor if you have already computed them\n",
        "!unzip \"query_tensors.zip\" -d query_tensors\n",
        "!unzip \"test_tensors.zip\" -d test_tensors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppQx1-td8oOc"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}