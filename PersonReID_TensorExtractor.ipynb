{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('pytorch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "fb220023fd2800431fe98a81f852d0ad5fc6056086b92ba5142182fcc04964c6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/PersonReID_TensorExtractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6jMA8w_8oOH"
      },
      "source": [
        "# Deep Learning Project - Person Re-Identification evaluation\n",
        "\n",
        "[https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/PersonReID_TensorExtractor.ipynb](https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/PersonReID_TensorExtractor.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8pDzzTQviv0"
      },
      "source": [
        "Importing from Google Drive the dataset.zip and extract into dataset folder, change the path with your dataset location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaPQ91Z78oOI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip \"/content/drive/MyDrive/UNITN/5° anno/Deep Learning 2021/dataset.zip\" -d dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg8kbiHv8oOL"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUDHglK08oOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c5d903-ac8f-4e45-ec9d-87b8610b98d9"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import Image\n",
        "import random\n",
        "import gc\n",
        "random.seed(10)\n",
        "# print cuda info\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda device count: {torch.cuda.device_count()}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda available: True\n",
            "Cuda device count: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwZMA17l8oOX"
      },
      "source": [
        "## Define Siamese Network\n",
        "This step is used to load the saved model and use it during testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9__1oD_z8oOX"
      },
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "class Siamese(nn.Module):\n",
        "\n",
        "    def __init__(self, resnet):\n",
        "        super(Siamese, self).__init__()\n",
        "        self.resnet = resnet\n",
        "        self.resnet.fc = Identity()\n",
        "        self.linear = torch.nn.Sequential(\n",
        "          torch.nn.Linear(in_features=2048, out_features=1024),\n",
        "          torch.nn.Linear(in_features=1024, out_features=512),\n",
        "          torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        out1 = self.forward_one(x1)\n",
        "        out2 = self.forward_one(x2)\n",
        "        return out1, out2\n",
        "\n",
        "'''\n",
        "Input arguments\n",
        "  num_classes: number of classes in the dataset.\n",
        "               This is equal to the number of output neurons.\n",
        "'''\n",
        "def initialize_resnet(num_classes):\n",
        "  #load pre-trained resnet\n",
        "  resnet = torchvision.models.resnet50(pretrained=True)\n",
        "  num_features = resnet.fc.in_features\n",
        "  resnet.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=num_features, out_features=1024),\n",
        "    torch.nn.Linear(in_features=1024, out_features=512),\n",
        "    torch.nn.Linear(in_features=512, out_features=num_classes),\n",
        "    torch.nn.Sigmoid()\n",
        "  )\n",
        "\n",
        "  return resnet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fINP--L08oOQ"
      },
      "source": [
        "class TestingDataset(Dataset):\n",
        "  def __init__(self, images, dir):\n",
        "      self.images = images\n",
        "      self.dir = dir\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "\n",
        "      img_name = self.images[idx]\n",
        "\n",
        "      image = Image.open(\"%s/%s\" % (self.dir, img_name))\n",
        "      image = T.ToTensor()(image)\n",
        "      image = F.interpolate(image, size=128)\n",
        "\n",
        "      sample = (image, img_name)\n",
        "      return sample"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN2uBss3MwXh"
      },
      "source": [
        "def compute_tensors(net, data_loader, target_dir):\n",
        "  if not os.path.exists(target_dir):\n",
        "    os.mkdir(target_dir)\n",
        "  for idx, (image, image_name) in enumerate(data_loader):\n",
        "    # Compute the forward pass\n",
        "    tensor = image.to('cuda:0')\n",
        "    tensor_to_save = net.forward_one(tensor)\n",
        "    torch.save(tensor_to_save, \"%s/%s.ph\"%(target_dir, image_name[0].split(\".\")[0]))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkS1HHdAYQ60"
      },
      "source": [
        "def extract_tensors(device='cuda:0', img_root='./dataset'):\n",
        "  # Instantiates the model\n",
        "  net = initialize_resnet(num_classes=56).to(device)\n",
        "  net = Siamese(net)\n",
        "  net.load_state_dict(torch.load(\"/content/drive/MyDrive/UNITN/5° anno/Deep Learning 2021/models/siamese_net_reid_resnet50_5epoch.pth\"))\n",
        "  net.to(device)\n",
        "  net.eval()\n",
        "  query = [f for f in listdir(\"./dataset/queries\")]\n",
        "  test = [f for f in listdir(\"./dataset/test\")]\n",
        "\n",
        "  testing_dataset = TestingDataset(images=test, dir=\"./dataset/test\")\n",
        "  test_dataloader = torch.utils.data.DataLoader(testing_dataset, 1, shuffle=False, num_workers=4) #before num_workers=4\n",
        "\n",
        "  query_dataset = TestingDataset(images=query, dir=\"./dataset/queries\")\n",
        "  query_dataloader = torch.utils.data.DataLoader(query_dataset, 1, shuffle=False, num_workers=2) #before num_workers=4\n",
        "\n",
        "  compute_tensors(net=net, data_loader=query_dataloader, target_dir=\"./dataset/query_tensors\")\n",
        "  compute_tensors(net=net, data_loader=test_dataloader, target_dir=\"./dataset/test_tensors\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAgt94Pk43bU"
      },
      "source": [
        "def main(threshold=0.036):\n",
        "\n",
        "  query_tensors = [f for f in listdir(\"./dataset/query_tensors\")]\n",
        "  query_images = [f for f in listdir(\"./dataset/queries\")]\n",
        "  test_tensors = [f for f in listdir(\"./dataset/test_tensors\")]\n",
        "  test_images = [f for f in listdir(\"./dataset/test\")]\n",
        "\n",
        "  query_tensors.sort()\n",
        "  query_images.sort()\n",
        "  test_tensors.sort()\n",
        "  test_images.sort()\n",
        "\n",
        "  test_tensors_cuda = []\n",
        "  for test in test_tensors:\n",
        "    test_tensor = torch.load(\"{}/{}\".format(\"./dataset/test_tensors\", test))\n",
        "    test_tensor.to('cuda:0')\n",
        "    test_tensors_cuda.append(test_tensor)\n",
        "\n",
        "  f = open(\"reid_results.txt\", \"w\")\n",
        "\n",
        "  for idxQ, query in enumerate(query_tensors):\n",
        "    if idxQ == 10:\n",
        "      break\n",
        "\n",
        "    print(query, \"doing\")\n",
        "    query_tensor = torch.load(\"{}/{}\".format(\"./dataset/query_tensors\", query))\n",
        "    query_tensor.to('cuda:0')\n",
        "\n",
        "    to_print = \"{}:\".format(query_images[idxQ])\n",
        "\n",
        "    for idxT, test in enumerate(test_tensors_cuda):\n",
        "      euclidean_distance = F.pairwise_distance(query_tensor, test)\n",
        "      if euclidean_distance.item() < threshold:\n",
        "        to_print = \"{}{},\".format(to_print, test_images[idxT])\n",
        "\n",
        "    f.write(to_print[:-1])\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "  f.close()\n",
        "      "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFovGLv2EbmU",
        "outputId": "488edc48-af24-4e10-8444-6cb56c5447fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#This is done to prevent memory overflow and use only the computed tensors during test phase, if you have already the zip files with tensors you can skip this phase\n",
        "extract_tensors()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykOukGdcJaVb",
        "outputId": "e9527dfa-ebd3-437c-915e-c03201332485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## Make a zip containing the tensors if need to save them\n",
        "#import shutil\n",
        "#shutil.make_archive('query_tensors', 'zip', './dataset/query_tensors')\n",
        "#shutil.make_archive('test_tensors', 'zip', './dataset/test_tensors')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/test_tensors.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppQx1-td8oOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c27ab95-6141-4b7d-97a2-d441bc3aacba"
      },
      "source": [
        "main()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "000000.ph doing\n",
            "000001.ph doing\n",
            "000002.ph doing\n",
            "000003.ph doing\n",
            "000004.ph doing\n",
            "000005.ph doing\n",
            "000006.ph doing\n",
            "000007.ph doing\n",
            "000008.ph doing\n",
            "000009.ph doing\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}