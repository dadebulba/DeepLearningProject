{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('pytorch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "fb220023fd2800431fe98a81f852d0ad5fc6056086b92ba5142182fcc04964c6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/DeepLearningProject_withaugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6jMA8w_8oOH"
      },
      "source": [
        "[https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/DeepLearningProject.ipynb](https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/DeepLearningProject.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaPQ91Z78oOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba43fb3-02da-4d86-fc0d-d9f959c4288d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSxDvJ0D8oOK"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/UNITN/5Â° anno/Deep Learning 2021/dataset.zip\" -d dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg8kbiHv8oOL"
      },
      "source": [
        "# Deep Learning Project\n",
        "## With augmentation (10/08)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUDHglK08oOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d9196b-2fad-4ee4-f645-563687ce2709"
      },
      "source": [
        "# import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import Image\n",
        "# print cuda info\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda device count: {torch.cuda.device_count()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda available: True\n",
            "Cuda device count: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1_3ydYU8oOO"
      },
      "source": [
        "# Dataset Preprocessing\n",
        "Make sure to extract the zip into the 'dataset' folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaU_EAEt8oOP"
      },
      "source": [
        "def setupLabelsDict(annotations_frame):\n",
        "   \n",
        "    labels = {}\n",
        "    index = 0\n",
        "    for i in list(annotations_frame):\n",
        "        if(i != \"id\"):\n",
        "            for j in range(min(annotations_frame[i]), max(annotations_frame[i])+1):\n",
        "                labels[f\"{i}-{j}\"] = index\n",
        "                index+=1\n",
        "    return labels\n",
        "\n",
        "def getTargetEncoding(id, annotations_frame, labels):\n",
        "    encoding = [0 for _ in range(len(labels))]\n",
        "    labels_df = annotations_frame.loc[annotations_frame['id'] == id]\n",
        "    for label, content in labels_df.items():\n",
        "        if(label != 'id'):\n",
        "            encoding[labels[\"%s-%s\" % (label, labels_df[label].iloc[0])]] += 1\n",
        "    return encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fINP--L08oOQ"
      },
      "source": [
        "class PeopleDataset(Dataset):\n",
        "    \"\"\"People with annotations dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, frame_with_labels, root_dir, labels, train, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.annotations_frame = frame_with_labels\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.img_files = [f for f in listdir(root_dir)]\n",
        "        self.labels = labels\n",
        "        self.train = train\n",
        "    def __len__(self):\n",
        "        return len(self.annotations_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        if self.train:\n",
        "            img_name = os.path.join(self.root_dir,self.annotations_frame.iloc[idx, 0])\n",
        "            image = Image.open(img_name)\n",
        "            if self.transform != None:\n",
        "              image = self.transform(image)\n",
        "            else:\n",
        "              image = T.ToTensor()(image)\n",
        "            image = F.interpolate(image, size=128)  \n",
        "            encoding = getTargetEncoding(self.annotations_frame.iloc[idx, 0],self.annotations_frame, self.labels)\n",
        "            sample = (image, torch.tensor(encoding))\n",
        "            return sample\n",
        "        else:\n",
        "            image = io.imread(self.img_files[idx])\n",
        "            image = T.ToTensor()(image)\n",
        "            image = F.interpolate(image, size=128)  \n",
        "            sample = image\n",
        "            return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ZU-pnv8oOS"
      },
      "source": [
        "def convertAnnotationsFrame(annotations_frame, train_dir):\n",
        "    annotations_frame = pd.read_csv('dataset/annotations_train.csv')\n",
        "\n",
        "    img_files = [f for f in listdir(train_dir)]\n",
        "\n",
        "    augmented_annotations_list = [] \n",
        "    for entry in annotations_frame.itertuples():\n",
        "        for i in img_files:\n",
        "            if(int(entry[1]) == int(i.split(\"_\")[0])):\n",
        "                img_with_annotation = {\n",
        "                    \"id\": i, \n",
        "                    \"age\": entry[2], \n",
        "                    \"backpack\":entry[3],\n",
        "                    \"bag\":entry[4],\n",
        "                    \"handbag\":entry[5],\n",
        "                    \"clothes\":entry[6],\n",
        "                    \"down\":entry[7],\n",
        "                    \"up\":entry[8],\n",
        "                    \"hair\":entry[9],\n",
        "                    \"hat\":entry[10],\n",
        "                    \"gender\":entry[11],\n",
        "                    \"upblack\":entry[12],\n",
        "                    \"upwhite\":entry[13],\n",
        "                    \"upred\":entry[14],\n",
        "                    \"uppurple\":entry[15],\n",
        "                    \"upyellow\":entry[16],\n",
        "                    \"upgray\":entry[17],\n",
        "                    \"upblue\":entry[18],\n",
        "                    \"upgreen\":entry[19],\n",
        "                    \"downblack\":entry[20],\n",
        "                    \"downwhite\":entry[21],\n",
        "                    \"downpink\":entry[22],\n",
        "                    \"downpurple\":entry[23],\n",
        "                    \"downyellow\":entry[24],\n",
        "                    \"downgray\":entry[25],\n",
        "                    \"downblue\":entry[26],\n",
        "                    \"downgreen\":entry[27],\n",
        "                    \"downbrown\":entry[28]\n",
        "                }\n",
        "                augmented_annotations_list.append(img_with_annotation)\n",
        "\n",
        "    augmented_annotations_frame = pd.DataFrame(augmented_annotations_list)\n",
        "    return augmented_annotations_frame\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj5sCxu18oOU"
      },
      "source": [
        "#labels = setupLabelsDict(augmented_annotations_frame)\n",
        "#print(augmented_annotations_frame.head())\n",
        "#id = augmented_annotations_frame.iloc[1, 0]\n",
        "#print(id)\n",
        "#labels_df = augmented_annotations_frame.loc[augmented_annotations_frame['id'] == id]\n",
        "#print(labels_df)\n",
        "#encoding = getTargetEncoding(augmented_annotations_frame.iloc[1, 0],augmented_annotations_frame, labels)\n",
        "#print(encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-O1rCrz8oOV"
      },
      "source": [
        "#labels = setupLabelsDict(annotations_frame)\n",
        "#print(len(labels))\n",
        "#print(labels)\n",
        "#people_dataset = PeopleDataset(frame_with_labels=augmented_annotations_frame,\n",
        "#                                    root_dir='./dataset/train',\n",
        "#                                    labels=labels)\n",
        "#\n",
        "#print(\"Dataset Initialized\")\n",
        "#dataloader = DataLoader(people_dataset, batch_size=1,\n",
        "#                        shuffle=True, num_workers=0)\n",
        "#print(\"DataLoader Initialized\")\n",
        "#print(len(people_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s891cbaj8oOW"
      },
      "source": [
        "#for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "#    print(batch_idx, type(inputs), targets)\n",
        "#    if batch_idx == 3:\n",
        "#        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwZMA17l8oOX"
      },
      "source": [
        "# Network\n",
        "## Fine tuning AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9__1oD_z8oOX"
      },
      "source": [
        "'''\n",
        "Input arguments\n",
        "  num_classes: number of classes in the dataset.\n",
        "               This is equal to the number of output neurons.\n",
        "'''\n",
        "\n",
        "def initialize_alexnet(num_classes):\n",
        "  # load the pre-trained Alexnet\n",
        "  #alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "  resnet = torchvision.models.resnet50(pretrained=True, progress=False)\n",
        "  num_features = resnet.fc.in_features\n",
        "  resnet.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=num_features, out_features=num_classes),\n",
        "    torch.nn.Sigmoid()\n",
        "  )\n",
        "  print(resnet)\n",
        "  # get the number of neurons in the penultimate layer\n",
        "  #in_features = alexnet.classifier[6].in_features\n",
        "  \n",
        "  # re-initalize the output layer\n",
        "  #alexnet.classifier[6] = torch.nn.Sequential(\n",
        "  #  torch.nn.Linear(in_features=in_features, out_features=num_classes),\n",
        "  #  torch.nn.Sigmoid()\n",
        "  #)\n",
        "  return resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy4p3NWR8oOY"
      },
      "source": [
        "Cost function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6rgB5208oOZ"
      },
      "source": [
        "def get_cost_function():\n",
        "  cost_function = torch.nn.BCELoss()\n",
        "  return cost_function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCxk8k3T8oOZ"
      },
      "source": [
        "Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmyQy5dx8oOZ"
      },
      "source": [
        "def get_optimizer(net, lr):\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "  return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE7Jo7Z08oOa"
      },
      "source": [
        "def test(net, data_loader, cost_function, num_classes, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  net.eval() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      # Load data into GPU\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(torch.float32) #converting to float for BCELoss\n",
        "      targets = targets.to(device)\n",
        "      #print(inputs.size())\n",
        "      #print(input)\n",
        "      #print(targets.size())\n",
        "      #print(targets)\n",
        "        \n",
        "      # Forward pass\n",
        "      outputs = net(inputs)\n",
        "      #print(outputs)\n",
        "      # Apply the loss\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      predicted = torch.round(outputs)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()/num_classes\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "def train(net,data_loader,optimizer,cost_function, num_classes, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  \n",
        "  net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "    # Load data into GPU\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(torch.float32) #converting to float for BCELoss\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # Apply the loss\n",
        "    loss = cost_function(outputs,targets)\n",
        "      \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Reset the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Better print something, no?\n",
        "    samples+=inputs.shape[0]\n",
        "    cumulative_loss += loss.item()\n",
        "    predicted = torch.round(outputs)\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()/num_classes\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVD-FE2e8oOb"
      },
      "source": [
        "def get_data(augmented_annotations_frame, labels, batch_size, img_root, test_batch_size=256):\n",
        "  \n",
        "  # Prepare data transformations and then combine them sequentially\n",
        "  # transform = list()\n",
        "  # transform.append(T.ToTensor())                            # converts Numpy to Pytorch Tensor\n",
        "  # transform.append(T.Normalize(mean=[0.5], std=[0.5]))      # Normalizes the Tensors between [-1, 1]\n",
        "  # transform = T.Compose(transform)                          # Composes the above transformations into one.\n",
        "  torchvision_transform = T.Compose([\n",
        "      T.Resize((256, 256)), \n",
        "      T.RandomCrop(224),\n",
        "      T.RandomHorizontalFlip(),\n",
        "      T.ToTensor(),\n",
        "      T.Normalize(\n",
        "          mean=[0.485, 0.456, 0.406],\n",
        "          std=[0.229, 0.224, 0.225],\n",
        "      )\n",
        "  ])\n",
        "\n",
        "  # Load data\n",
        "  full_training_data = PeopleDataset(frame_with_labels=augmented_annotations_frame,\n",
        "                                      root_dir=\"%s/train\" % (img_root),\n",
        "                                      labels=labels,\n",
        "                                      train=True,\n",
        "                                      transform=torchvision_transform)\n",
        "  \n",
        "  test_data = PeopleDataset(frame_with_labels=augmented_annotations_frame,\n",
        "                                      root_dir=\"%s/test\" % (img_root),\n",
        "                                      labels=labels,\n",
        "                                      train=False)\n",
        "\n",
        "  #print(\"Dataset Initialized\")\n",
        "  #dataloader = DataLoader(people_dataset, batch_size=,\n",
        "  #                        shuffle=True, num_workers=0)\n",
        "  #print(\"DataLoader Initialized\")\n",
        "  #print(len(people_dataset))\n",
        "  #full_training_data = torchvision.datasets.MNIST('./dataset', train=True, transform=transform, download=True) \n",
        "  #test_data = torchvision.datasets.MNIST('./dataset', train=False, transform=transform, download=True) \n",
        "  \n",
        "\n",
        "  # Create train and validation splits\n",
        "  num_samples = len(full_training_data)\n",
        "  training_samples = int(num_samples*0.5+1)\n",
        "  validation_samples = num_samples - training_samples\n",
        "\n",
        "  training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n",
        "  \n",
        "  # Initialize dataloaders\n",
        "  train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True, num_workers=0)       #before num_workers=4\n",
        "  val_loader = torch.utils.data.DataLoader(validation_data, test_batch_size, shuffle=False, num_workers=0) #before num_workers=4\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, test_batch_size, shuffle=False, num_workers=0) #before num_workers=4\n",
        "  \n",
        "  return train_loader, val_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnndkhgI8oOb"
      },
      "source": [
        "def log_values(writer, step, loss, accuracy, prefix):\n",
        "  writer.add_scalar(f\"{prefix}/loss\", loss, step)\n",
        "  writer.add_scalar(f\"{prefix}/accuracy\", accuracy, step)\n",
        "\n",
        "def main(batch_size=128, \n",
        "         device='cuda:0', \n",
        "         learning_rate=0.001, \n",
        "         epochs=20, \n",
        "         img_root='./dataset'):\n",
        "  from torch.utils.tensorboard import SummaryWriter\n",
        "  writer = SummaryWriter(log_dir=\"runs/exp1\")\n",
        "\n",
        "  annotations_frame = pd.read_csv(\"./dataset/annotations_train.csv\")\n",
        "  augmented_annotations_frame = convertAnnotationsFrame(annotations_frame, \"%s/train\" % (img_root))\n",
        "  labels = setupLabelsDict(augmented_annotations_frame)\n",
        "\n",
        "  # Instantiates dataloaders\n",
        "  train_loader, val_loader, test_loader = get_data(augmented_annotations_frame=augmented_annotations_frame, labels=labels, batch_size=batch_size, img_root=img_root)\n",
        "  \n",
        "  # Instantiates the model\n",
        "  net = initialize_alexnet(num_classes=len(labels)).to(device)\n",
        "  \n",
        "  # Instantiates the optimizer\n",
        "  optimizer = get_optimizer(net, learning_rate)\n",
        "  \n",
        "  # Instantiates the cost function\n",
        "  cost_function = get_cost_function()\n",
        "\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader, cost_function, num_classes=len(labels))\n",
        "  val_loss, val_accuracy = test(net, val_loader, cost_function, num_classes=len(labels))\n",
        "  #test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  log_values(writer, -1, train_loss, train_accuracy, \"Train\")\n",
        "  log_values(writer, -1, val_loss, val_accuracy, \"Validation\")\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  #print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  for e in range(epochs):\n",
        "    train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function, num_classes=len(labels))\n",
        "    val_loss, val_accuracy = test(net, val_loader, cost_function, num_classes=len(labels))\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "    log_values(writer, e, train_loss, train_accuracy, \"Train\")\n",
        "    log_values(writer, e, val_loss, val_accuracy, \"Validation\")\n",
        "  print('After training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader, cost_function, num_classes=len(labels))\n",
        "  val_loss, val_accuracy = test(net, val_loader, cost_function, num_classes=len(labels))\n",
        "  #test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "  log_values(writer, e, train_loss, train_accuracy, \"Train\")\n",
        "  log_values(writer, e, val_loss, val_accuracy, \"Validation\")\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  #print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "  # Closes the logger\n",
        "  writer.close()\n",
        "  return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqom_4Hz8oOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18945a27-a3b1-46f2-b275-d30598ad8370"
      },
      "source": [
        "# Free GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# clear runs\n",
        "! rm -r runs\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "183"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppQx1-td8oOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28af290-8400-49ba-e9af-daed0b2f5be5"
      },
      "source": [
        "net = main()\n",
        "torch.save(net.state_dict(), \"./resnet_with_augmentation_20epoch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=56, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Before training:\n",
            "\t Training loss 0.00155, Training accuracy 47.38\n",
            "\t Validation loss 0.00310, Validation accuracy 47.36\n",
            "-----------------------------------------------------\n",
            "Epoch: 1\n",
            "\t Training loss 0.00068, Training accuracy 85.21\n",
            "\t Validation loss 0.00126, Validation accuracy 87.54\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Training loss 0.00036, Training accuracy 93.18\n",
            "\t Validation loss 0.00082, Validation accuracy 91.74\n",
            "-----------------------------------------------------\n",
            "Epoch: 3\n",
            "\t Training loss 0.00029, Training accuracy 94.67\n",
            "\t Validation loss 0.00067, Validation accuracy 93.51\n",
            "-----------------------------------------------------\n",
            "Epoch: 4\n",
            "\t Training loss 0.00022, Training accuracy 96.00\n",
            "\t Validation loss 0.00066, Validation accuracy 93.56\n",
            "-----------------------------------------------------\n",
            "Epoch: 5\n",
            "\t Training loss 0.00018, Training accuracy 96.85\n",
            "\t Validation loss 0.00057, Validation accuracy 94.53\n",
            "-----------------------------------------------------\n",
            "Epoch: 6\n",
            "\t Training loss 0.00014, Training accuracy 97.73\n",
            "\t Validation loss 0.00048, Validation accuracy 95.44\n",
            "-----------------------------------------------------\n",
            "Epoch: 7\n",
            "\t Training loss 0.00010, Training accuracy 98.49\n",
            "\t Validation loss 0.00051, Validation accuracy 95.23\n",
            "-----------------------------------------------------\n",
            "Epoch: 8\n",
            "\t Training loss 0.00009, Training accuracy 98.81\n",
            "\t Validation loss 0.00041, Validation accuracy 96.23\n",
            "-----------------------------------------------------\n",
            "Epoch: 9\n",
            "\t Training loss 0.00006, Training accuracy 99.28\n",
            "\t Validation loss 0.00042, Validation accuracy 96.19\n",
            "-----------------------------------------------------\n",
            "Epoch: 10\n",
            "\t Training loss 0.00005, Training accuracy 99.50\n",
            "\t Validation loss 0.00034, Validation accuracy 96.99\n",
            "-----------------------------------------------------\n",
            "Epoch: 11\n",
            "\t Training loss 0.00004, Training accuracy 99.65\n",
            "\t Validation loss 0.00034, Validation accuracy 97.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 12\n",
            "\t Training loss 0.00003, Training accuracy 99.78\n",
            "\t Validation loss 0.00028, Validation accuracy 97.53\n",
            "-----------------------------------------------------\n",
            "Epoch: 13\n",
            "\t Training loss 0.00002, Training accuracy 99.88\n",
            "\t Validation loss 0.00025, Validation accuracy 97.79\n",
            "-----------------------------------------------------\n",
            "Epoch: 14\n",
            "\t Training loss 0.00002, Training accuracy 99.92\n",
            "\t Validation loss 0.00024, Validation accuracy 97.94\n",
            "-----------------------------------------------------\n",
            "Epoch: 15\n",
            "\t Training loss 0.00001, Training accuracy 99.94\n",
            "\t Validation loss 0.00024, Validation accuracy 97.96\n",
            "-----------------------------------------------------\n",
            "After training:\n",
            "\t Training loss 0.00001, Training accuracy 99.91\n",
            "\t Validation loss 0.00024, Validation accuracy 97.96\n",
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}